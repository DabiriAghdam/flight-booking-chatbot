{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-Model-Intent-And-Slot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwZ0OpWdLmJ5"
      },
      "source": [
        "<h3 align=center> In His Name, the Most High </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGj7KgpmLkLp"
      },
      "source": [
        "#importing libraries\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp6szjCnHU3v"
      },
      "source": [
        "def readIOB(filename, drop_list):\n",
        "  words_list = list() # a list of list of words for every sentence in dataset\n",
        "  tags_list = list() # a list of list of IOB tags for every sentence in dataset\n",
        "  intents_list = list() # a list of intent for every sentence in dataset\n",
        "  data = list() # a list of dicts contaiting above data in a more structured form\n",
        "  vocabs = set() # a set containing whole dataset words\n",
        "\n",
        "  with open(filename) as f:\n",
        "    for line in f.readlines():\n",
        "        line = line.strip().split()\n",
        "        \n",
        "        index = 0\n",
        "        words = list()\n",
        "        for i, word in enumerate(line[:-1]):\n",
        "            if (word == 'EOS'):\n",
        "                index = i\n",
        "                break\n",
        "            if (word != 'BOS'): \n",
        "                # word = re.sub(r'[^\\w\\s]', '', word) # removing punctuations\n",
        "                word = re.sub(r\"[?|'|!|.]\",\"\", word) # removing punctuations\n",
        "                word = word.lower() # lowerizing word\n",
        "                words.append(word) \n",
        "                vocabs.add(word)\n",
        "        \n",
        "        tags = list()\n",
        "        for tag in line[index:-1]:\n",
        "            tags.append(tag)\n",
        "                    \n",
        "        # handling entries with multiple intents\n",
        "        intent = \"\"\n",
        "        if ('#' in line[-1]): \n",
        "            for item in line[-1].split('#'):\n",
        "                intent = item\n",
        "                break\n",
        "        else: intent = line[-1]\n",
        "\n",
        "        if (intent not in drop_list): #dropping \n",
        "          words_list.append(words)\n",
        "          tags_list.append(tags)\n",
        "          intents_list.append(intent)\n",
        "          data.append({\n",
        "              # 'sentence': ' '.join(words),\n",
        "              'words': words,\n",
        "              'iob_tags': tags,\n",
        "              'length': len(words),\n",
        "              'intent': intent})\n",
        "          \n",
        "\n",
        "  word_dict = {'UNK': 0, 'PAD': 1}\n",
        "  for i, item in enumerate(sorted(vocabs)):\n",
        "    word_dict[item] = i + 2\n",
        "\n",
        "  tags = set()\n",
        "  for item in tags_list:\n",
        "    for tag in item:\n",
        "      tags.add(tag)\n",
        "  slot_dict = dict()\n",
        "  for i, item in enumerate(sorted(tags)):\n",
        "    slot_dict[item] = i\n",
        "\n",
        "  intent_dict = dict()\n",
        "  for i, item in enumerate(sorted(set(intents_list))):\n",
        "    intent_dict[item] = i\n",
        "\n",
        "  return intent_dict, slot_dict, word_dict, words_list, tags_list, intents_list, sorted(vocabs), data\n",
        "\n",
        "\n",
        "def dataStatistics(tags_list, intents_list, vocabs):\n",
        "  print('dataset vocab size:', len(vocabs))\n",
        "  print('# of dataset rows:', len(intents_list))\n",
        "  print('# of dataset unique intents:', len(set(intents_list)))\n",
        "  print('# of dataset unique IOB tags:', len(set([tag for item in tags_list for tag in item])))\n",
        "\n",
        "  print('-' * 35 + '\\nintents distribution:') \n",
        "  intents_freq = dict()\n",
        "  for intent in set(intents_list):\n",
        "      intents_freq[intent] = intents_list.count(intent)\n",
        "  for key in intents_freq:\n",
        "      value = intents_freq[key]\n",
        "      print('%s: %d (%.2f%%),' % (key, value, value / len(intents_list) * 100))\n",
        "  print()\n",
        "  plt.figure(figsize=(24, 8))\n",
        "  plt.bar(list(intents_freq.keys()),intents_freq.values())\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n' + '-' * 35 + '\\ntags distribution:')\n",
        "  tags_freq = dict()\n",
        "  count = 0\n",
        "  for item in tags_list:\n",
        "      for tag in item:\n",
        "          if (tag in tags_freq): tags_freq[tag] += 1 \n",
        "          else: tags_freq[tag] = 1\n",
        "          count += 1\n",
        "  for key in tags_freq:\n",
        "      value = tags_freq[key]\n",
        "      print('%s: %d (%.2f%%),' % (key, value, value / count * 100))\n",
        "    \n",
        "  return intents_freq, tags_freq"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4gzTrOmLRyw"
      },
      "source": [
        "drop_list = ['atis_cheapest', 'atis_city', 'atis_restriction', 'atis_meal', 'atis_distance', 'atis_airport', 'atis_capacity', 'atis_ground_fare','atis_flight_no']"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq6lJsR-LS3j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da25b346-5460-4d84-8b22-2ae49168da89"
      },
      "source": [
        "#importing train data\n",
        "train_intent_dict, train_tag_dict, train_word_dict, train_words, train_tags, train_intents, train_vocabs, train_data = readIOB('atis-train-final-w-intent.iob', drop_list = drop_list)\n",
        "train_intents_freq, train_tags_freq = dataStatistics(train_tags, train_intents, train_vocabs)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset vocab size: 1000\n",
            "# of dataset rows: 4770\n",
            "# of dataset unique intents: 8\n",
            "# of dataset unique IOB tags: 120\n",
            "-----------------------------------\n",
            "intents distribution:\n",
            "atis_airfare: 874 (18.32%),\n",
            "atis_airline: 293 (6.14%),\n",
            "atis_flight_time: 112 (2.35%),\n",
            "atis_quantity: 100 (2.10%),\n",
            "atis_abbreviation: 152 (3.19%),\n",
            "atis_ground_service: 524 (10.99%),\n",
            "atis_aircraft: 161 (3.38%),\n",
            "atis_flight: 2554 (53.54%),\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------\n",
            "tags distribution:\n",
            "EOS: 4770 (8.07%),\n",
            "O: 34467 (58.31%),\n",
            "B-transport_type: 60 (0.10%),\n",
            "I-transport_type: 29 (0.05%),\n",
            "B-city_name: 395 (0.67%),\n",
            "B-airport_name: 50 (0.08%),\n",
            "I-airport_name: 63 (0.11%),\n",
            "B-airline_name: 680 (1.15%),\n",
            "B-fromloc.city_name: 3952 (6.69%),\n",
            "B-toloc.city_name: 3958 (6.70%),\n",
            "I-toloc.city_name: 1041 (1.76%),\n",
            "B-aircraft_code: 22 (0.04%),\n",
            "B-cost_relative: 455 (0.77%),\n",
            "B-round_trip: 486 (0.82%),\n",
            "I-round_trip: 496 (0.84%),\n",
            "B-fare_basis_code: 79 (0.13%),\n",
            "I-fare_basis_code: 2 (0.00%),\n",
            "I-airline_name: 402 (0.68%),\n",
            "I-fromloc.city_name: 602 (1.02%),\n",
            "B-depart_date.day_name: 716 (1.21%),\n",
            "B-depart_time.period_of_day: 521 (0.88%),\n",
            "B-airline_code: 146 (0.25%),\n",
            "B-flight_number: 123 (0.21%),\n",
            "B-depart_time.time_relative: 289 (0.49%),\n",
            "B-depart_time.time: 336 (0.57%),\n",
            "B-meal_description: 42 (0.07%),\n",
            "B-class_type: 320 (0.54%),\n",
            "I-class_type: 273 (0.46%),\n",
            "B-depart_date.today_relative: 80 (0.14%),\n",
            "I-city_name: 93 (0.16%),\n",
            "B-depart_date.month_name: 387 (0.65%),\n",
            "B-depart_date.day_number: 403 (0.68%),\n",
            "B-fromloc.airport_name: 90 (0.15%),\n",
            "I-fromloc.airport_name: 110 (0.19%),\n",
            "B-toloc.state_name: 71 (0.12%),\n",
            "I-cost_relative: 73 (0.12%),\n",
            "B-or: 53 (0.09%),\n",
            "I-depart_time.time: 272 (0.46%),\n",
            "B-fromloc.airport_code: 13 (0.02%),\n",
            "B-toloc.airport_code: 25 (0.04%),\n",
            "B-meal: 36 (0.06%),\n",
            "B-stoploc.city_name: 197 (0.33%),\n",
            "I-depart_date.day_number: 112 (0.19%),\n",
            "B-flight_mod: 256 (0.43%),\n",
            "B-arrive_time.time_relative: 158 (0.27%),\n",
            "B-arrive_time.time: 170 (0.29%),\n",
            "I-arrive_time.time: 137 (0.23%),\n",
            "B-fare_amount: 71 (0.12%),\n",
            "I-fare_amount: 69 (0.12%),\n",
            "B-flight_time: 126 (0.21%),\n",
            "B-depart_date.date_relative: 75 (0.13%),\n",
            "B-flight_days: 28 (0.05%),\n",
            "B-state_code: 7 (0.01%),\n",
            "I-flight_time: 48 (0.08%),\n",
            "B-arrive_date.date_relative: 10 (0.02%),\n",
            "B-arrive_date.day_name: 73 (0.12%),\n",
            "B-arrive_time.period_of_day: 58 (0.10%),\n",
            "B-toloc.airport_name: 32 (0.05%),\n",
            "I-toloc.airport_name: 41 (0.07%),\n",
            "B-fromloc.state_code: 38 (0.06%),\n",
            "I-flight_mod: 10 (0.02%),\n",
            "B-arrive_time.period_mod: 4 (0.01%),\n",
            "I-arrive_time.time_relative: 2 (0.00%),\n",
            "B-flight_stop: 143 (0.24%),\n",
            "B-meal_code: 6 (0.01%),\n",
            "B-arrive_date.month_name: 45 (0.08%),\n",
            "B-arrive_date.day_number: 45 (0.08%),\n",
            "B-fromloc.state_name: 35 (0.06%),\n",
            "I-fromloc.state_name: 8 (0.01%),\n",
            "B-depart_time.start_time: 16 (0.03%),\n",
            "B-depart_time.end_time: 16 (0.03%),\n",
            "I-depart_time.end_time: 11 (0.02%),\n",
            "B-toloc.state_code: 81 (0.14%),\n",
            "I-meal_code: 4 (0.01%),\n",
            "B-stoploc.state_code: 4 (0.01%),\n",
            "B-airport_code: 27 (0.05%),\n",
            "B-depart_time.period_mod: 39 (0.07%),\n",
            "I-depart_time.period_of_day: 7 (0.01%),\n",
            "B-connect: 36 (0.06%),\n",
            "B-economy: 49 (0.08%),\n",
            "B-arrive_time.start_time: 15 (0.03%),\n",
            "I-arrive_time.start_time: 6 (0.01%),\n",
            "B-arrive_time.end_time: 14 (0.02%),\n",
            "I-arrive_time.end_time: 14 (0.02%),\n",
            "B-mod: 39 (0.07%),\n",
            "I-toloc.state_name: 11 (0.02%),\n",
            "I-stoploc.city_name: 34 (0.06%),\n",
            "I-flight_stop: 15 (0.03%),\n",
            "B-return_date.date_relative: 7 (0.01%),\n",
            "B-day_name: 10 (0.02%),\n",
            "B-period_of_day: 8 (0.01%),\n",
            "B-restriction_code: 19 (0.03%),\n",
            "B-depart_date.year: 23 (0.04%),\n",
            "B-today_relative: 4 (0.01%),\n",
            "I-today_relative: 6 (0.01%),\n",
            "I-restriction_code: 14 (0.02%),\n",
            "B-month_name: 4 (0.01%),\n",
            "B-day_number: 4 (0.01%),\n",
            "B-return_date.month_name: 5 (0.01%),\n",
            "B-return_date.day_number: 5 (0.01%),\n",
            "B-toloc.country_name: 3 (0.01%),\n",
            "B-time_relative: 2 (0.00%),\n",
            "B-time: 4 (0.01%),\n",
            "I-time: 2 (0.00%),\n",
            "B-stoploc.airport_name: 1 (0.00%),\n",
            "I-depart_time.start_time: 7 (0.01%),\n",
            "I-economy: 12 (0.02%),\n",
            "B-state_name: 3 (0.01%),\n",
            "I-arrive_date.day_number: 8 (0.01%),\n",
            "I-depart_date.today_relative: 12 (0.02%),\n",
            "I-arrive_time.period_of_day: 3 (0.01%),\n",
            "B-arrive_date.today_relative: 2 (0.00%),\n",
            "B-return_date.today_relative: 1 (0.00%),\n",
            "I-return_date.today_relative: 2 (0.00%),\n",
            "B-days_code: 3 (0.01%),\n",
            "I-depart_time.time_relative: 2 (0.00%),\n",
            "B-return_time.period_of_day: 2 (0.00%),\n",
            "I-return_date.day_number: 1 (0.00%),\n",
            "I-meal_description: 2 (0.00%),\n",
            "B-return_time.period_mod: 1 (0.00%),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H9R18SOM8AK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "092f1508-9ccc-43ab-f028-d31f83e01e29"
      },
      "source": [
        "#importing test data\n",
        "test_intent_dict, test_tag_dict, train_word_dict, test_words, test_tags, test_intents, test_vocabs, test_data = readIOB('atis-test-final-w-intent.iob', drop_list = drop_list)\n",
        "test_intents_freq, test_tags_freq = dataStatistics(test_tags, test_intents, test_vocabs)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset vocab size: 412\n",
            "# of dataset rows: 816\n",
            "# of dataset unique intents: 9\n",
            "# of dataset unique IOB tags: 99\n",
            "-----------------------------------\n",
            "intents distribution:\n",
            "atis_day_name: 2 (0.25%),\n",
            "atis_airfare: 49 (6.00%),\n",
            "atis_airline: 38 (4.66%),\n",
            "atis_flight_time: 1 (0.12%),\n",
            "atis_quantity: 3 (0.37%),\n",
            "atis_abbreviation: 33 (4.04%),\n",
            "atis_flight: 645 (79.04%),\n",
            "atis_ground_service: 36 (4.41%),\n",
            "atis_aircraft: 9 (1.10%),\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------\n",
            "tags distribution:\n",
            "EOS: 816 (8.74%),\n",
            "O: 5044 (54.02%),\n",
            "B-fromloc.city_name: 688 (7.37%),\n",
            "B-toloc.city_name: 700 (7.50%),\n",
            "I-toloc.city_name: 256 (2.74%),\n",
            "B-stoploc.city_name: 20 (0.21%),\n",
            "I-stoploc.city_name: 10 (0.11%),\n",
            "B-depart_date.month_name: 56 (0.60%),\n",
            "B-depart_date.day_number: 55 (0.59%),\n",
            "B-depart_time.time_relative: 63 (0.67%),\n",
            "B-depart_time.time: 55 (0.59%),\n",
            "I-depart_time.time: 50 (0.54%),\n",
            "B-round_trip: 73 (0.78%),\n",
            "I-round_trip: 71 (0.76%),\n",
            "B-airline_name: 87 (0.93%),\n",
            "I-airline_name: 60 (0.64%),\n",
            "B-depart_date.day_name: 209 (2.24%),\n",
            "B-depart_time.period_of_day: 129 (1.38%),\n",
            "I-fromloc.city_name: 176 (1.88%),\n",
            "B-meal_description: 9 (0.10%),\n",
            "B-depart_date.date_relative: 17 (0.18%),\n",
            "B-arrive_time.time_relative: 31 (0.33%),\n",
            "B-arrive_time.time: 33 (0.35%),\n",
            "I-arrive_time.time: 34 (0.36%),\n",
            "B-return_date.day_name: 2 (0.02%),\n",
            "B-arrive_date.date_relative: 2 (0.02%),\n",
            "B-arrive_date.day_name: 11 (0.12%),\n",
            "B-flight_stop: 21 (0.22%),\n",
            "B-depart_date.today_relative: 9 (0.10%),\n",
            "B-toloc.state_name: 28 (0.30%),\n",
            "B-arrive_date.month_name: 6 (0.06%),\n",
            "B-arrive_date.day_number: 6 (0.06%),\n",
            "B-arrive_time.start_time: 8 (0.09%),\n",
            "B-arrive_time.end_time: 8 (0.09%),\n",
            "I-arrive_time.end_time: 8 (0.09%),\n",
            "B-airport_name: 15 (0.16%),\n",
            "I-airport_name: 21 (0.22%),\n",
            "B-connect: 6 (0.06%),\n",
            "B-fromloc.airport_name: 8 (0.09%),\n",
            "I-fromloc.airport_name: 7 (0.07%),\n",
            "B-return_date.date_relative: 3 (0.03%),\n",
            "I-return_date.date_relative: 3 (0.03%),\n",
            "B-arrive_time.period_of_day: 6 (0.06%),\n",
            "B-fromloc.state_name: 17 (0.18%),\n",
            "I-depart_date.day_number: 15 (0.16%),\n",
            "I-depart_time.period_of_day: 1 (0.01%),\n",
            "B-cost_relative: 37 (0.40%),\n",
            "I-cost_relative: 3 (0.03%),\n",
            "B-flight_time: 1 (0.01%),\n",
            "I-flight_time: 1 (0.01%),\n",
            "B-flight_mod: 24 (0.26%),\n",
            "B-flight_number: 7 (0.07%),\n",
            "B-city_name: 35 (0.37%),\n",
            "I-city_name: 17 (0.18%),\n",
            "B-airline_code: 33 (0.35%),\n",
            "B-toloc.airport_code: 4 (0.04%),\n",
            "B-depart_time.start_time: 3 (0.03%),\n",
            "B-depart_time.end_time: 3 (0.03%),\n",
            "I-depart_time.end_time: 3 (0.03%),\n",
            "B-toloc.airport_name: 3 (0.03%),\n",
            "I-toloc.airport_name: 3 (0.03%),\n",
            "B-aircraft_code: 13 (0.14%),\n",
            "B-toloc.country_name: 1 (0.01%),\n",
            "B-class_type: 23 (0.25%),\n",
            "B-compartment: 1 (0.01%),\n",
            "B-meal_code: 1 (0.01%),\n",
            "B-day_name: 2 (0.02%),\n",
            "B-meal: 11 (0.12%),\n",
            "B-toloc.state_code: 17 (0.18%),\n",
            "B-fromloc.state_code: 23 (0.25%),\n",
            "I-class_type: 16 (0.17%),\n",
            "B-depart_time.period_mod: 5 (0.05%),\n",
            "B-fromloc.airport_code: 5 (0.05%),\n",
            "B-fare_basis_code: 17 (0.18%),\n",
            "B-flight_days: 10 (0.11%),\n",
            "B-depart_date.year: 3 (0.03%),\n",
            "B-period_of_day: 4 (0.04%),\n",
            "I-flight_mod: 6 (0.06%),\n",
            "B-transport_type: 4 (0.04%),\n",
            "B-state_code: 1 (0.01%),\n",
            "B-restriction_code: 4 (0.04%),\n",
            "I-restriction_code: 3 (0.03%),\n",
            "B-airport_code: 9 (0.10%),\n",
            "B-mod: 1 (0.01%),\n",
            "B-days_code: 1 (0.01%),\n",
            "I-arrive_time.time_relative: 4 (0.04%),\n",
            "B-or: 3 (0.03%),\n",
            "B-stoploc.airport_code: 1 (0.01%),\n",
            "I-depart_time.time_relative: 1 (0.01%),\n",
            "B-economy: 6 (0.06%),\n",
            "B-booking_class: 1 (0.01%),\n",
            "B-fare_amount: 2 (0.02%),\n",
            "I-fare_amount: 2 (0.02%),\n",
            "B-flight: 1 (0.01%),\n",
            "I-depart_time.start_time: 1 (0.01%),\n",
            "I-arrive_time.start_time: 1 (0.01%),\n",
            "I-transport_type: 1 (0.01%),\n",
            "I-fromloc.state_name: 1 (0.01%),\n",
            "I-toloc.state_name: 1 (0.01%),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_foO07JMNpzx"
      },
      "source": [
        "temp = set()\n",
        "for tag in train_intent_dict:\n",
        "  temp.add(tag)\n",
        "for tag in test_intent_dict:\n",
        "  temp.add(tag)\n",
        "f = open('vocab.intents','w')\n",
        "for item in sorted(temp):\n",
        "  f.write(item + '\\n')\n",
        "f.close()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH6KFC5QOr-L"
      },
      "source": [
        "temp = set()\n",
        "for tag in train_tag_dict:\n",
        "  temp.add(tag)\n",
        "for tag in test_tag_dict:\n",
        "  temp.add(tag)\n",
        "f = open('vocab.tags','w')\n",
        "for item in sorted(temp):\n",
        "  f.write(item + '\\n')\n",
        "f.close()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP1e_Yk_a0gR"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "total_epoch = 50#500\n",
        "max_len = 50\n",
        "for item in train_data:\n",
        "  if (item['length'] > max_len): max_len = item['length']\n",
        "for item in test_data:\n",
        "  if (item['length'] > max_len): max_len = item['length']\n",
        "\n",
        "batch = 16\n",
        "learning_rate = 0.001\n",
        "DROPOUT = 0.2 # 0.2, 0.3, 0.4\n",
        "\n",
        "embedding_size = 300\n",
        "lstm_hidden_size = 200"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rMDJL0BFcWW"
      },
      "source": [
        "# Make tag dict \n",
        "train_tag_dict = {}\n",
        "\n",
        "with open('vocab.tags') as f:\n",
        "    for i, line in enumerate(f.readlines()):\n",
        "        train_tag_dict[line.strip()] = i"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDn4j1Z_FoNZ"
      },
      "source": [
        "# Make intent dict \n",
        "train_intent_dict = {}\n",
        "\n",
        "with open('vocab.intents') as f:\n",
        "    for i, line in enumerate(f.readlines()):\n",
        "        train_intent_dict[line.strip()] = i"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v71hcyVjddmq"
      },
      "source": [
        "index2slot_dict = {}\n",
        "for key in train_tag_dict:\n",
        "    index2slot_dict[train_tag_dict[key]] = key\n",
        "\n",
        "# index2slot_dict[len(train_tag_dict)] = 'unk' #unknown?"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7UYUV3jedKv"
      },
      "source": [
        "def intent2index(intent, intent_dict=train_intent_dict):\n",
        "  # if (intent in intent_dict.keys()): return intent_dict[intent]\n",
        "  # else: return 'unk'\n",
        "  return intent_dict[intent]\n",
        "\n",
        "def tags2index(tags, tags_dict=train_tag_dict):\n",
        "  tagsindex = list()\n",
        "  for tag in tags:\n",
        "    # if(tag in tags_dict.keys()): tagsindex.append(tags_dict[tag])\n",
        "    # else: tagsindex.append(len(tags_dict)) #unknown?\n",
        "    tagsindex.append(tags_dict[tag])\n",
        "  \n",
        "  while len(tagsindex) < max_len:\n",
        "    tagsindex.append(tags_dict['O'])\n",
        "\n",
        "  return tagsindex\n",
        "\n",
        "def words2index(words, word_dict=train_word_dict):\n",
        "  sentence = list()\n",
        "  for word in words:\n",
        "    if word in word_dict:\n",
        "      sentence.append(word_dict[word])\n",
        "    else:\n",
        "      sentence.append(word_dict['UNK'])\n",
        "\n",
        "  while len(sentence) < max_len:\n",
        "    sentence.append(word_dict['PAD'])\n",
        "\n",
        "  return sentence\n",
        "\n",
        "def make_mask(real_len, max_len=max_len, label_size=len(train_tag_dict), batch=batch):\n",
        "    mask = torch.zeros(batch, max_len, label_size)\n",
        "    for index, item in enumerate(real_len):\n",
        "        mask[index, :item, :] = 1.0\n",
        "    return mask\n",
        "\n",
        "\n",
        "def masked_log_softmax(vector: torch.Tensor, mask: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
        "    if mask is not None:\n",
        "        mask = mask.float()\n",
        "        while mask.dim() < vector.dim():\n",
        "            mask = mask.unsqueeze(1)\n",
        "        \n",
        "        vector = vector + (mask + 1e-45).log()\n",
        "    return F.log_softmax(vector, dim=dim)\n",
        "\n",
        "\n",
        "def one_hot(array, Num=len(train_tag_dict), maxlen=max_len):\n",
        "\n",
        "    shape = array.size()\n",
        "    batch = shape[0]\n",
        "    if len(shape) == 1:\n",
        "        res = torch.zeros(batch, Num)\n",
        "        for i in range(batch):\n",
        "            res[i][array[i]] = 1\n",
        "    else:\n",
        "        res = torch.zeros(batch, maxlen, Num)\n",
        "        for i in range(batch):\n",
        "            for j in range(maxlen):\n",
        "                if array[i, j] == Num:\n",
        "                    pass\n",
        "                else:\n",
        "                    res[i][j][array[i, j]] = 1\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def get_batch(data, batch_size=batch):\n",
        "    random.shuffle(data)\n",
        "    sindex = 0\n",
        "    eindex = batch_size\n",
        "    while eindex < len(data):\n",
        "        orig_sentence = []\n",
        "        sentence = []\n",
        "        real_len = []\n",
        "        slot_label = []\n",
        "        intent_label = []\n",
        "         \n",
        "        batch = data[sindex:eindex]\n",
        "        for m in range(sindex, eindex):\n",
        "            orig_sentence.append(' '.join(data[m]['words']))\n",
        "            sentence.append(words2index(data[m]['words']))\n",
        "            real_len.append(data[m]['length'])\n",
        "            slot_label.append(tags2index(data[m]['iob_tags']))\n",
        "            intent_label.append(intent2index(data[m]['intent']))\n",
        "\n",
        "        temp = eindex\n",
        "        eindex = eindex + batch_size\n",
        "        sindex = temp\n",
        "\n",
        "        yield (orig_sentence, sentence, real_len, slot_label, intent_label)\n",
        "\n",
        "def get_chunks(labels):\n",
        "    chunks = []\n",
        "    start_idx,end_idx = 0,0\n",
        "    for idx in range(1,len(labels)-1):\n",
        "        chunkStart, chunkEnd = False,False\n",
        "        if labels[idx-1] not in ('O', '<pad>', '<unk>', '<s>', '</s>', '<STOP>', '<START>'):\n",
        "            prevTag, prevType = labels[idx-1][:1], labels[idx-1][2:]\n",
        "        else:\n",
        "            prevTag, prevType = 'O', 'O'\n",
        "        if labels[idx] not in ('O', '<pad>', '<unk>', '<s>', '</s>', '<STOP>', '<START>'):\n",
        "            Tag, Type = labels[idx][:1], labels[idx][2:]\n",
        "        else:\n",
        "            Tag, Type = 'O', 'O'\n",
        "        if labels[idx+1] not in ('O', '<pad>', '<unk>', '<s>', '</s>', '<STOP>', '<START>'):\n",
        "            nextTag, nextType = labels[idx+1][:1], labels[idx+1][2:]\n",
        "        else:\n",
        "            nextTag, nextType = 'O', 'O'\n",
        "\n",
        "        if (Tag == 'B' and prevTag in ('B', 'I', 'O')) or (prevTag, Tag) in [('O', 'I'), ('E', 'E'), ('E', 'I'), ('O', 'E')]:\n",
        "            chunkStart = True\n",
        "        if Tag != 'O' and prevType != Type:\n",
        "            chunkStart = True\n",
        "\n",
        "        if (Tag in ('B','I') and nextTag in ('B','O')) or (Tag == 'E' and nextTag in ('E', 'I', 'O')):\n",
        "            chunkEnd = True\n",
        "        if Tag != 'O' and Type != nextType:\n",
        "            chunkEnd = True\n",
        "\n",
        "        if chunkStart:\n",
        "            start_idx = idx\n",
        "        if chunkEnd:\n",
        "            end_idx = idx\n",
        "            chunks.append((start_idx,end_idx,Type))\n",
        "            start_idx,end_idx = 0,0\n",
        "    return chunks"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoxv_rm1Y4Hw"
      },
      "source": [
        "# Bi-model \n",
        "class slot_enc(nn.Module):\n",
        "    def __init__(self, embedding_size, lstm_hidden_size, vocab_size=len(train_word_dict)):\n",
        "        super(slot_enc, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size).to(device)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size=lstm_hidden_size, num_layers=2,\\\n",
        "                            bidirectional= True, batch_first=True) #, dropout=DROPOUT)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = F.dropout(x, DROPOUT)       \n",
        "        x, _ = self.lstm(x)\n",
        "        x = F.dropout(x, DROPOUT)\n",
        "        return x \n",
        "\n",
        "\n",
        "class slot_dec(nn.Module):\n",
        "    def __init__(self, lstm_hidden_size, label_size=len(train_tag_dict)):\n",
        "        super(slot_dec, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=lstm_hidden_size*5, hidden_size=lstm_hidden_size, num_layers=1)\n",
        "        self.fc = nn.Linear(lstm_hidden_size, label_size)\n",
        "        self.hidden_size = lstm_hidden_size\n",
        "\n",
        "    def forward(self, x, hi):\n",
        "        batch = x.size(0)\n",
        "        length = x.size(1)\n",
        "        dec_init_out = torch.zeros(batch, 1, self.hidden_size).to(device)\n",
        "        hidden_state = (torch.zeros(1, 1, self.hidden_size).to(device), \\\n",
        "                        torch.zeros(1, 1, self.hidden_size).to(device))\n",
        "        x = torch.cat((x, hi), dim=-1)\n",
        "\n",
        "        x = x.transpose(1, 0)  # 50 x batch x feature_size\n",
        "        x = F.dropout(x, DROPOUT)\n",
        "        all_out = []\n",
        "        for i in range(length):\n",
        "            if i == 0:\n",
        "                out, hidden_state = self.lstm(torch.cat((x[i].unsqueeze(1), dec_init_out), dim=-1), hidden_state)\n",
        "            else:\n",
        "                out, hidden_state = self.lstm(torch.cat((x[i].unsqueeze(1), out), dim=-1), hidden_state)\n",
        "            all_out.append(out)\n",
        "        output = torch.cat(all_out, dim=1) # 50 x batch x feature_size\n",
        "        x = F.dropout(x, DROPOUT)\n",
        "        res = self.fc(output)\n",
        "        return res \n",
        "\n",
        "\n",
        "class intent_enc(nn.Module):\n",
        "    def __init__(self, embedding_size, lstm_hidden_size, vocab_size=len(train_word_dict)):\n",
        "        super(intent_enc, self).__init__()\n",
        "\t\t\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size).to(device)\n",
        "        # self.embedding.weight.data.uniform_(-1.0, 1.0)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size= lstm_hidden_size, num_layers=2,\\\n",
        "                            bidirectional= True, batch_first=True, dropout=DROPOUT)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = F.dropout(x, DROPOUT)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = F.dropout(x, DROPOUT)\n",
        "        return x\n",
        "\n",
        "\n",
        "class intent_dec(nn.Module):\n",
        "    def __init__(self, lstm_hidden_size, label_size=len(train_intent_dict)):\n",
        "        super(intent_dec, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=lstm_hidden_size*4, hidden_size=lstm_hidden_size, batch_first=True, num_layers=1)#, dropout=DROPOUT)\n",
        "        self.fc = nn.Linear(lstm_hidden_size, label_size)\n",
        "        \n",
        "    def forward(self, x, hs, real_len):\n",
        "        batch = x.size()[0]\n",
        "        real_len = torch.tensor(real_len).to(device)\n",
        "        x = torch.cat((x, hs), dim=-1)\n",
        "        x = F.dropout(x, DROPOUT)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = F.dropout(x, DROPOUT)\n",
        "\n",
        "        index = torch.arange(batch).long().to(device)\n",
        "        state = x[index, real_len-1, :]\n",
        "        \n",
        "        res = self.fc(state.squeeze())\n",
        "        return res\n",
        "        \n",
        "\n",
        "\n",
        "class Intent(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Intent, self).__init__()\n",
        "        self.enc = intent_enc(embedding_size, lstm_hidden_size).to(device)\n",
        "        self.dec = intent_dec(lstm_hidden_size).to(device)\n",
        "        self.share_memory = torch.zeros(batch, max_len, lstm_hidden_size * 2).to(device)\n",
        "    \n",
        "\n",
        "class Slot(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Slot, self).__init__()\n",
        "        self.enc = slot_enc(embedding_size, lstm_hidden_size).to(device)\n",
        "        self.dec = slot_dec(lstm_hidden_size).to(device)\n",
        "        self.share_memory = torch.zeros(batch, max_len, lstm_hidden_size * 2).to(device)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwLz2SYjBMMn"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 1\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XymVFvoOc5Io",
        "outputId": "45e52f6b-cbd2-4515-953b-faa1a71aee24"
      },
      "source": [
        "epoch_num = total_epoch\n",
        "\n",
        "# load the entire model.\n",
        "# intent_model = torch.load('model_intent_best.ckpt').to(device)\n",
        "# slot_model = torch.load('model_slot_best.ckpt').to(device)\n",
        "# slot_model = Slot().to(device)\n",
        "# intent_model = Intent().to(device)\n",
        "\n",
        "print(slot_model)\n",
        "print(intent_model)\n",
        "\n",
        "slot_optimizer = optim.Adam(slot_model.parameters(), lr=learning_rate)       # optim.Adamax\n",
        "intent_optimizer = optim.Adam(intent_model.parameters(), lr=learning_rate)   # optim.Adamax\n",
        "\n",
        "best_correct_num = 0\n",
        "best_epoch = -1\n",
        "best_F1_score = 0.0\n",
        "best_epoch_slot = -1\n",
        "for epoch in range(epoch_num):\n",
        "    slot_loss_history = []\n",
        "    intent_loss_history = []\n",
        "    for batch_index, data in enumerate(get_batch(train_data)): \n",
        "\n",
        "\t    # Preparing data\n",
        "        _, sentence, real_len, slot_label, intent_label = data\n",
        "\n",
        "        mask = make_mask(real_len).to(device)\n",
        "        x = torch.tensor(sentence).to(device)\n",
        "        y_slot = torch.tensor(slot_label).to(device)\n",
        "        y_slot = one_hot(y_slot).to(device)\n",
        "        y_intent = torch.tensor(intent_label).to(device)\n",
        "        y_intent = one_hot(y_intent, Num=len(train_intent_dict)).to(device)\n",
        "\n",
        "\t\t# Calculate compute graph\n",
        "        slot_optimizer.zero_grad()\n",
        "        intent_optimizer.zero_grad()\n",
        "\t\t\n",
        "        hs = slot_model.enc(x)\n",
        "        slot_model.share_memory = hs.clone()\n",
        "\n",
        "        hi = intent_model.enc(x)\n",
        "        intent_model.share_memory = hi.clone()\n",
        "\t\t\n",
        "\t\t\n",
        "        slot_logits = slot_model.dec(hs, intent_model.share_memory.detach())\n",
        "        log_slot_logits = masked_log_softmax(slot_logits, mask, dim=-1)\n",
        "        slot_loss = -1.0*torch.sum(y_slot*log_slot_logits)\n",
        "        slot_loss_history.append(slot_loss.item())\n",
        "        slot_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(slot_model.parameters(), 5.0)\n",
        "        slot_optimizer.step()\n",
        "\n",
        "        # Asynchronous training\n",
        "        intent_logits = intent_model.dec(hi, slot_model.share_memory.detach(), real_len)\n",
        "        log_intent_logits = F.log_softmax(intent_logits, dim=-1)\n",
        "        intent_loss = -1.0*torch.sum(y_intent*log_intent_logits)\n",
        "        intent_loss_history.append(intent_loss.item())\n",
        "        intent_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(intent_model.parameters(), 5.0)\n",
        "        intent_optimizer.step()\n",
        "        \n",
        "\t\t# Log\n",
        "        if batch_index % 100 == 0 and batch_index > 0:\n",
        "            print('Slot loss: {:.4f} \\t Intent loss: {:.4f}'.format(sum(slot_loss_history[-100:])/100.0, \\\n",
        "                sum(intent_loss_history[-100:])/100.0))\n",
        "\n",
        "    # Evaluation \n",
        "    total_test = len(test_data)\n",
        "    correct_num = 0\n",
        "    TP, FP, FN = 0, 0, 0\n",
        "    for batch_index, data_test in enumerate(get_batch(test_data, batch_size=1)):\n",
        "        orig_sentence_test, sentence_test, real_len_test, slot_label_test, intent_label_test = data_test\n",
        "        # print(sentence[0].shape, real_len.shape, slot_label.shape)\n",
        "        x_test = torch.tensor(sentence_test).to(device)\n",
        "\n",
        "        mask_test = make_mask(real_len_test, batch=1).to(device)\n",
        "        # Slot model generate hs_test and intent model generate hi_test\n",
        "        hs_test = slot_model.enc(x_test)\n",
        "        hi_test = intent_model.enc(x_test)\n",
        "\n",
        "        # Slot\n",
        "        slot_logits_test = slot_model.dec(hs_test, hi_test)\n",
        "        log_slot_logits_test = masked_log_softmax(slot_logits_test, mask_test, dim=-1)\n",
        "        slot_pred_test = torch.argmax(log_slot_logits_test, dim=-1)\n",
        "        # Intent\n",
        "        intent_logits_test = intent_model.dec(hi_test, hs_test, real_len_test)\n",
        "        log_intent_logits_test = F.log_softmax(intent_logits_test, dim=-1)\n",
        "        res_test = torch.argmax(log_intent_logits_test, dim=-1)\n",
        "        \n",
        "\n",
        "        if res_test.item() == intent_label_test[0]:\n",
        "            correct_num += 1\n",
        "        if correct_num > best_correct_num:\n",
        "            best_correct_num = correct_num\n",
        "            best_epoch = epoch\n",
        "\t\t\t# Save and load the entire model.\n",
        "            # torch.save(intent_model, 'model_intent_best.ckpt')\n",
        "            # torch.save(slot_model, 'model_slot_best.ckpt')\n",
        "    \n",
        "        # Calc slot F1 score\n",
        "        # print(slot_pred_test)\n",
        "        # print(slot_label_test)\n",
        "        slot_pred_test = slot_pred_test[0][:real_len_test[0]]\n",
        "        slot_label_test = slot_label_test[0][:real_len_test[0]]\n",
        "\n",
        "        slot_pred_test = [int(item) for item in slot_pred_test]\n",
        "        slot_label_test = [int(item) for item in slot_label_test]\n",
        "\n",
        "        slot_pred_test = [index2slot_dict[item] for item in slot_pred_test]\n",
        "        slot_label_test = [index2slot_dict[item] for item in slot_label_test]\n",
        "        \n",
        "        pred_chunks = get_chunks(['O'] + slot_pred_test + ['O']) \n",
        "        label_chunks = get_chunks(['O'] + slot_label_test + ['O'])\n",
        "\n",
        "        # print(orig_sentence_test)\n",
        "        # print(slot_pred_test)\n",
        "        # print(slot_label_test)\n",
        "        # print('pred')\n",
        "        # print(pred_chunks)\n",
        "        # print('label')\n",
        "        # print(label_chunks)\n",
        "        # if(batch_index == 2): a\n",
        "\n",
        "        for pred_chunk in pred_chunks:\n",
        "            if pred_chunk in label_chunks:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FP += 1\n",
        "        for label_chunk in label_chunks:\n",
        "            if label_chunk not in pred_chunks:\n",
        "                FN += 1\n",
        "\n",
        "    F1_score = 100.0*2*TP/(2*TP+FN+FP)\n",
        "    if F1_score > best_F1_score:\n",
        "        best_F1_score = F1_score\n",
        "        best_epoch_slot = epoch\n",
        "    print('*' * 20)\n",
        "    print('Epoch: [{}/{}], Intent Val Acc: {:.4f} \\t Slot F1 score: {:.4f}'.format(epoch+1, epoch_num, 100.0*correct_num/total_test, F1_score))\n",
        "    print('*' * 20)\n",
        "    \n",
        "    print('Best Intent Acc: {:.4f} at Epoch: [{}]'.format(100.0*best_correct_num/total_test, best_epoch+1))\n",
        "    print('Best F1 score: {:.4f} at Epoch: [{}]'.format(best_F1_score, best_epoch_slot+1))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slot(\n",
            "  (enc): slot_enc(\n",
            "    (embedding): Embedding(414, 300)\n",
            "    (lstm): LSTM(300, 200, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (dec): slot_dec(\n",
            "    (lstm): LSTM(1000, 200)\n",
            "    (fc): Linear(in_features=200, out_features=126, bias=True)\n",
            "  )\n",
            ")\n",
            "Intent(\n",
            "  (enc): intent_enc(\n",
            "    (embedding): Embedding(414, 300)\n",
            "    (lstm): LSTM(300, 200, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  )\n",
            "  (dec): intent_dec(\n",
            "    (lstm): LSTM(800, 200, batch_first=True)\n",
            "    (fc): Linear(in_features=200, out_features=9, bias=True)\n",
            "  )\n",
            ")\n",
            "Slot loss: 1.0356 \t Intent loss: 0.0001\n",
            "Slot loss: 2.1992 \t Intent loss: 0.0000\n",
            "********************\n",
            "Epoch: [1/5], Intent Val Acc: 98.4069 \t Slot F1 score: 91.1526\n",
            "********************\n",
            "Best Intent Acc: 98.4069 at Epoch: [1]\n",
            "Best F1 score: 91.1526 at Epoch: [1]\n",
            "Slot loss: 0.6650 \t Intent loss: 0.7132\n",
            "Slot loss: 0.9677 \t Intent loss: 0.2262\n",
            "********************\n",
            "Epoch: [2/5], Intent Val Acc: 99.0196 \t Slot F1 score: 91.2321\n",
            "********************\n",
            "Best Intent Acc: 99.0196 at Epoch: [2]\n",
            "Best F1 score: 91.2321 at Epoch: [2]\n",
            "Slot loss: 2.8457 \t Intent loss: 0.0011\n",
            "Slot loss: 1.6822 \t Intent loss: 0.0003\n",
            "********************\n",
            "Epoch: [3/5], Intent Val Acc: 98.4069 \t Slot F1 score: 91.6433\n",
            "********************\n",
            "Best Intent Acc: 99.0196 at Epoch: [2]\n",
            "Best F1 score: 91.6433 at Epoch: [3]\n",
            "Slot loss: 0.5791 \t Intent loss: 0.0083\n",
            "Slot loss: 0.6275 \t Intent loss: 0.1932\n",
            "********************\n",
            "Epoch: [4/5], Intent Val Acc: 98.2843 \t Slot F1 score: 90.6808\n",
            "********************\n",
            "Best Intent Acc: 99.0196 at Epoch: [2]\n",
            "Best F1 score: 91.6433 at Epoch: [3]\n",
            "Slot loss: 1.5851 \t Intent loss: 0.0282\n",
            "Slot loss: 2.3887 \t Intent loss: 0.1434\n",
            "********************\n",
            "Epoch: [5/5], Intent Val Acc: 98.6520 \t Slot F1 score: 93.0880\n",
            "********************\n",
            "Best Intent Acc: 99.0196 at Epoch: [2]\n",
            "Best F1 score: 93.0880 at Epoch: [5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ9HPGXplZ1k"
      },
      "source": [
        "# Save the entire model\n",
        "torch.save(intent_model, 'model_intent_best.ckpt')\n",
        "torch.save(slot_model, 'model_slot_best.ckpt')"
      ],
      "execution_count": 64,
      "outputs": []
    }
  ]
}